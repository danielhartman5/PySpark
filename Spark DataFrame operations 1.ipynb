{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9518128f597d7b00dc14729602cfd87fb7b2cf75925976bcb0d0e328a830a12b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
    "\n",
    "df = spark.read.json(\"people.json\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- age: long (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame[summary: string, age: string, name: string]\n",
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "\n",
    "print(df.describe().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\nroot\n |-- age: integer (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Define Schema manually\n",
    "from pyspark.sql.types import (StructField, StringType,\n",
    "                                IntegerType, StructType)\n",
    "\n",
    "data_schema = [StructField(\"age\", IntegerType(), nullable = True),\n",
    "               StructField(\"name\", StringType(), True)]\n",
    "                # last atr is that it can be null or not\n",
    "\n",
    "final_struct = StructType(fields = data_schema)\n",
    "\n",
    "df = spark.read.json(\"people.json\", schema = final_struct)\n",
    "\n",
    "df.show()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Column<b'age'>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# select columns an single columns\n",
    "df[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame[age: int]\n+----+\n| age|\n+----+\n|null|\n|  30|\n|  19|\n+----+\n\n"
     ]
    }
   ],
   "source": [
    "# selecting columns as dataframes\n",
    "print(df.select(\"age\"))\n",
    "df.select(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "df.head(2) # row object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-------+------+\n| age|   name|newage|\n+----+-------+------+\n|null|Michael|  null|\n|  30|   Andy|    40|\n|  19| Justin|    29|\n+----+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# add new column\n",
    "df.withColumn(\"newage\", df[\"age\"]+10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+-------+------+\n|age_newname|   name|newage|\n+-----------+-------+------+\n|       null|Michael|  null|\n|         30|   Andy|    40|\n|         19| Justin|    29|\n+-----------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"newage\", df[\"age\"]+10).withColumnRenamed(\"age\",\"age_newname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using SQL queries\n",
    "# 1. register as SQL temporary view\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "# 2. write query\n",
    "results = spark.sql(\"SELECT * FROM people\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+----+\n|age|name|\n+---+----+\n| 30|Andy|\n+---+----+\n\n"
     ]
    }
   ],
   "source": [
    "results2 = spark.sql(\"SELECT * FROM people where age > 20\")\n",
    "results2.show()"
   ]
  }
 ]
}